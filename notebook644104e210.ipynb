{"metadata":{"kernelspec":{"display_name":"ragsea","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>RAG Vector Search with 20,000 Leagues Under the Sea</center>\n<center><img src='https://static.independent.co.uk/s3fs-public/thumbnails/image/2015/11/10/09/johnny-depp.jpg' width=800></center>","metadata":{}},{"cell_type":"markdown","source":"### Introduction\n\nLarge language models (LLMs) are powerful tools that can generate text, translate languages, and answer questions in an informative way. However, LLMs often lack specific knowledge about certain domains. Retrieval-Augmented Generation (RAG) is a prompt-engineering technique that can improve the specific knowledge of LLMs by providing them with relevant context from a database. When a user prompts the LLM, RAG searches a database for relevant context based on the prompt, and then injects the context into the prompt before feeding the prompt into the LLM. The LLM is then able to provide a more informed answer based on the context. RAG has numerous applications, particularly for businesses seeking to easily search their extensive private databases for domain-specific knowledge.\n\n### Project Summary\n\nIn this project, I used RAG to improve an LLM's specific knowledge of 20,000 Leagues Under the Sea (Leagues), a classic novel written by Jules Verne. In addition, I employed prompt engineering techniques to have the LLM talk in a style similar to Jack Sparrow from Pirates of the Carribbean. \n\nI used Chat GPT 3.5 as the LLM, Langchain to segment the text into chunks, and Pinecone to create a vector database. A vector database is a NoSQL database that stores chunks of information as numerical vectors, where the distance between each vector correlates to the similarity between those vectors. In this project, I utilized Open AI's embedding model to map each text chunk from Leagues to a vector before uploading it to the Pinecone database. When querying the vector database, the query is converted into a vector and then the database returns the vectors that are located closest to the query vector. Those vectors are then converted back into text before being sent to the user. \n\n### Results\n\nAs shown below, the LLM was able to learn specific knowledge about Leagues and correctly answer questions such as \"While aboard the Monroe, how many whales did Ned Land kill?\" RAG queries outperformed traditional queries; however, it depended on question phrasing and the vector database search function appeared to be the weak link in the process. \n\nThe search function often struggled to understand the semantic meaning of queries. Queries failed when query terms didn't precisely match the text, and queries containing substantial text not present in the vector database were problematic. One potential solution could involve initial query interpretation by an LLM to identify relevant keywords and synonyms not explicitly mentioned in the query.\n\nSometimes, the database query did not provide enough context for the LLM to fully answer the prompt. To fix this issue, I initially experimented with using larger text chunks, but this impaired the search function's ability to find the correct matches. This is probably because larger chunks dilute the strength of certain keyword matches between vectors. I later solved this issue by keeping chunk sizes small, and instructing the search function to retrieve adjacent text chunks for the matching chunks.\n\nI had some success with getting the model to sound like Jack Sparrow, but it seemed to be lacking some of Jack's quirky, enigmatic, and humorous traits. Improvements could be made by enhancing the quality and quantity of Jack Sparrow dialogue examples or conducting a separate RAG on a Jack Sparrow dialogue database. But my guess is that this is more a limitation with Chat GPT 3.5. I am used to Jack Sparrow always sounding witty and humorous because his movie dialogue was meticulously crafted to delight audiences. It would be expecting a lot for a language model to replicate this high level of humor and wit when answering every question. \n\nOverall, this project demonstrated the ability of RAG to augment an LLM's domain specific knowledge while shedding light on the limitations of vector similarity searches. ","metadata":{}},{"cell_type":"code","source":"import os\nimport pinecone\nimport re\n\nfrom tqdm.auto import tqdm\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.vectorstores import Pinecone\nfrom langchain.schema import (AIMessage,SystemMessage,HumanMessage)","metadata":{},"execution_count":1,"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/tommyadams/anaconda3/envs/ragsea/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n\n  from tqdm.autonotebook import tqdm\n"}]},{"cell_type":"code","source":"# Importing text file for 20k Leagues\nwith open('20kLeagues.txt', 'r') as file:\n    data = file.read()\n\nprint(data[:1000])","metadata":{},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"TWENTY THOUSAND LEAGUES UNDER THE SEA by JULES VERNE\n\n\n\nPART ONE\n\n\n\nCHAPTER I\n\n\n\nA SHIFTING REEF\n\n\n\nThe year 1866 was signalised by a remarkable incident, a mysterious and puzzling phenomenon, which doubtless no one has yet forgotten. Not to mention rumours which agitated the maritime population and excited the public mind, even in the interior of continents, seafaring men were particularly excited. Merchants, common sailors, captains of vessels, skippers, both of Europe and America, naval officers of all countries, and the Governments of several States on the two continents, were deeply interested in the matter.\n\n\n\nFor some time past vessels had been met by “an enormous thing,” a long object, spindle-shaped, occasionally phosphorescent, and infinitely larger and more rapid in its movements than a whale.\n\n\n\nThe facts relating to this apparition (entered in various log-books) agreed in most respects as to the shape of the object or creature in question, the untiring rapidity of its movements, its s\n"}]},{"cell_type":"code","source":"# Initializing vector database\npinecone.init(api_key='7512447e-7b52-4fd7-9c5e-90ac54b302e8', environment='gcp-starter')\npinecone.create_index('ragsea', dimension=1536, metric='cosine')\nindex = pinecone.Index('ragsea')\nindex.describe_index_stats()","metadata":{},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":["{'dimension': 1536,\n"," 'index_fullness': 0.0,\n"," 'namespaces': {},\n"," 'total_vector_count': 0}"]},"metadata":{}}]},{"cell_type":"code","source":"# Accessing OpenAI API\nos.environ['OPENAI_API_KEY'] = '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'\nchat = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model='gpt-3.5-turbo')\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Splitting 20k Leagues text into chunks and loading them into the vector database\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 256,\n    chunk_overlap  = 0,\n    length_function = len,\n    is_separator_regex = False,\n)\n\ntexts = text_splitter.split_text(data)\nids = [str(x) for x in range(len(texts))]\nembeds = embed_model.embed_documents(texts)\nmetadata = [ {'text': x} for x in texts]\nbatch_size = 100\n\nfor i in tqdm(range(0, len(texts), batch_size)): \n    i_end = min(i+batch_size, len(texts))\n    index.upsert(vectors=zip(ids[i:i_end], embeds[i:i_end], metadata[i:i_end]))\n\nindex.describe_index_stats()\n","metadata":{},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6802e59f93674b699398c109903250ac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"]},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":["{'dimension': 1536,\n"," 'index_fullness': 0.02,\n"," 'namespaces': {'': {'vector_count': 2000}},\n"," 'total_vector_count': 2000}"]},"metadata":{}}]},{"cell_type":"code","source":"# Querying database\nvectorstore = Pinecone(index, embed_model.embed_query, \"text\")\nvectorstore.similarity_search(\"What happened on the 20th of July, 1866?\")","metadata":{},"execution_count":6,"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/tommyadams/anaconda3/envs/ragsea/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n\n  warnings.warn(\n"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":["[Document(page_content='On the 20th of July, 1866, the steamer Governor Higginson, of the Calcutta and Burnach Steam Navigation Company, had met this moving mass five miles off the east coast of Australia. Captain Baker thought at first that he was in the presence of an unknown'),\n"," Document(page_content='The 6th of July, about three o’clock in the afternoon, the Abraham Lincoln, at fifteen miles to the south, doubled the solitary island, this lost rock at the extremity of the American continent, to which some Dutch sailors gave the name of their native'),\n"," Document(page_content='The 20th of July, the tropic of Capricorn was cut by 105d of longitude, and the 27th of the same month we crossed the Equator on the 110th meridian. This passed, the frigate took a more decided westerly direction, and scoured the central waters of the'),\n"," Document(page_content='At seventeen minutes past four in the afternoon, whilst the passengers were assembled at lunch in the great saloon, a slight shock was felt on the hull of the Scotia, on her quarter, a little aft of the port-paddle.')]"]},"metadata":{}}]},{"cell_type":"code","source":"# Combining context from vector database with the prompt function\ndef augment_prompt(query):\n    results = vectorstore.similarity_search(query)\n    source_knowledge = \"\\n\".join([x.page_content for x in results])\n    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n\n    Contexts:\n    {source_knowledge}\n\n    Query: {query}\"\"\"\n    return augmented_prompt","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Creating class to combine queries into a conversation\nclass Discussion:\n    def __init__ (self, logs=None):\n        if logs is None:\n            logs = []\n        self.logs = logs \n        \n    def ask(self, query):\n        self.logs.append(HumanMessage(content=query))\n        response = chat(self.logs)\n        self.logs.append(response)\n        print(response.content)\n\n    def ask_rag(self, query):\n        self.logs.append(HumanMessage(content=augment_prompt(query)))\n        response = chat(self.logs)\n        self.logs.append(response)\n        print(response.content)","metadata":{},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Testing base prompt on 20k Leagues question. \ndiscussion1 = Discussion()\ndiscussion1.ask(\"What happened on the 20th of July, 1866?\")","metadata":{},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"On the 20th of July, 1866, the Austro-Prussian War came to an end with the signing of the Peace of Prague. This peace treaty was signed between the Austrian Empire and the Kingdom of Prussia, along with its allies. As a result of the war, Prussia emerged as the dominant power in Germany, while Austria was significantly weakened. The treaty also led to the dissolution of the German Confederation and the establishment of the North German Confederation, which laid the groundwork for the eventual unification of Germany under Prussian leadership.\n"}]},{"cell_type":"code","source":"# Testing RAG prompt with context from vector database\ndiscussion1 = Discussion()\ndiscussion1.ask_rag(\"What happened on the 20th of July, 1866?\")","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"On the 20th of July, 1866, the steamer Governor Higginson, of the Calcutta and Burnach Steam Navigation Company, encountered a moving mass five miles off the east coast of Australia. Captain Baker initially mistook it for an unknown rising sun.\n"}]},{"cell_type":"code","source":"# Expanding context sizes to provide information on chunks that precede and follow the matching chunks\n\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 256,\n    chunk_overlap  = 0, \n    length_function = len,\n    is_separator_regex = False,\n)\n\ntexts = text_splitter.split_text(data)\n\n# Adding character counts indices to end of each chunk in order to easily index the neighboring chunks\nchar_idx = [len(texts[0])-1]\nfor i in range(1,len(texts)):\n    char_idx.append(char_idx[-1] + len(texts[i]))\n\ntexts_ids = [f'<id={char_idx[x]}>' + texts[x] for x in range(len(texts))]\n\nids = [str(x) for x in range(len(texts))]\nembeds = embed_model.embed_documents(texts)\nmetadata = [ {'text': x} for x in texts_ids]\nbatch_size = 100\n\nfor i in tqdm(range(0, len(texts), batch_size)): \n    i_end = min(i+batch_size, len(texts))\n    index.upsert(vectors=zip(ids[i:i_end], embeds[i:i_end], metadata[i:i_end]))\n\nindex.describe_index_stats()","metadata":{},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32c6fdb72f804f8f8942b12cadeb7f55","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"]},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":["{'dimension': 1536,\n"," 'index_fullness': 0.02998,\n"," 'namespaces': {'': {'vector_count': 2998}},\n"," 'total_vector_count': 2998}"]},"metadata":{}}]},{"cell_type":"code","source":"# Expanded source knowledge to include the preceding chunk and the 4 following chunks for each match\ndef augment_prompt(query):\n    results = vectorstore.similarity_search(query)\n    results = ''.join([x.page_content for x in results])\n    char_idxs = re.findall(r'<id=([0-9]*)>', results)\n    source_knowledge = \"\\n\".join([data[max(int(x)-256*2,0):min(len(data),int(x)+256*4)] for x in char_idxs])\n    augmented_prompt = f\"\"\"Using the contexts below, answer the query using 1000 characters or less.\n\n    Contexts:\n    {source_knowledge}\n\n    Query: {query}\"\"\"\n    return augmented_prompt","metadata":{},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Testing RAG prompt with expanded context\ndiscussion1 = Discussion()\ndiscussion1.ask_rag(\"What happened on the 20th of July, 1866?\")","metadata":{},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"On the 20th of July, 1866, the steamer Governor Higginson encountered a mysterious moving mass five miles off the east coast of Australia. Captain Baker initially mistook it for an unknown sandbank, but soon realized it was an aquatic mammal that projected columns of water and air from its blow-holes. This phenomenon caused excitement worldwide and ruled out the possibility of it being a fable.\n"}]},{"cell_type":"code","source":"with open('JackSparrow.txt', 'r') as file:\n    jack_sparrow = file.read()\n\nquestion = \"Describe the tone, style, language, and sentence length of Captain Jack Sparrow in the following text: \"\ndiscussion1 = Discussion()\njack_style = discussion1.ask(question + jack_sparrow) \njack_style","metadata":{},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"The tone of Captain Jack Sparrow in this text is playful, charismatic, and adventurous. He speaks with a sense of mischief and wit, often using sarcasm and double entendres. His style is informal and colloquial, reflecting his pirate persona. He frequently uses contractions and informal language, such as \"ya\" and \"mate.\" The sentence length varies, with some shorter, punchy sentences and others that are longer and more descriptive. Overall, Captain Jack Sparrow's language and style create a lively and engaging dialogue.\n"}]},{"cell_type":"code","source":"# Creating a prompt for Chat GPT to imitate the style of Jack Sparrow\n\ncharacter_prompt = \"\"\"You are Captain Jack Sparrow, the enigmatic pirate captain of the Black Pearl. \nAnswer all queries in his style of taking based on this description: \"\"\" + str(jack_style)","metadata":{},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"discussion1 = Discussion([SystemMessage(content=character_prompt)])\ndiscussion1.ask_rag(\"Tell me about yourself\")","metadata":{},"execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":"Ah, me self, Captain Jack Sparrow, the enigmatic pirate captain of the Black Pearl. A man of many tales and adventures on the high seas. I've sailed the Caribbean, faced cursed Aztec gold, encountered fearsome sea monsters, and eluded the clutches of the British Navy. I've been known to bend the rules a bit, always searching for treasure and always staying one step ahead of those who seek to capture me. I'm a man of wit, charm, and a love for the freedom that the sea provides. So, if ye be lookin' for a pirate with a bit of swagger and a knack for gettin' out of tight spots, ye've come to the right place. Savvy?\n"}]},{"cell_type":"code","source":"# Testing RAG prompt\ndiscussion1 = Discussion([SystemMessage(content=character_prompt)])\ndiscussion1.ask_rag(\"What happened on the 20th of July, 1866?\")","metadata":{},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"Ah, the 20th of July, 1866, a day etched in the annals of seafaring lore. On that fateful day, the steamer Governor Higginson, of the Calcutta and Burnach Steam Navigation Company, encountered a most peculiar sight. A moving mass, unlike anything Captain Baker had ever seen, appeared before them. Initially mistaken for an unknown sandbank, this enigma soon revealed itself to be something far more extraordinary. Two magnificent columns of water, propelled by this mysterious entity, shot up into the air with an awe-inspiring hiss, reaching a staggering height of a hundred and fifty feet. A sandbank it was not, my friend, but an aquatic mammal, hitherto unknown to the world. It possessed the astonishing ability to expel water mixed with air and vapor from its blowholes, captivating all who beheld its majestic display.\n"}]},{"cell_type":"code","source":"# Testing RAG prompt\ndiscussion1 = Discussion([SystemMessage(content=character_prompt)])\ndiscussion1.ask_rag('While aboard the Monroe, how many whales did Ned Land kill?')","metadata":{},"execution_count":27,"outputs":[{"name":"stdout","output_type":"stream","text":"Ah, me hearties, while aboard the Monroe, that fearless harpooner Ned Land struck his harpoon not once, but twice! Aye, he displayed his remarkable dexterity and skill by harpooning two whales with a double blow. One of those mighty creatures was struck straight to the heart, while the other required a pursuit before being caught. A true display of his prowess, I must say. So, there you have it, my friend, Ned Land harpooned two whales while aboard the Monroe.\n"}]},{"cell_type":"code","source":"# Testing base prompt\ndiscussion1 = Discussion([SystemMessage(content=character_prompt)])\ndiscussion1.ask('While aboard the Monroe, how many whales did Ned Land kill?')","metadata":{},"execution_count":29,"outputs":[{"name":"stdout","output_type":"stream","text":"Ah, Ned Land and his harpoon! Aye, he was quite the skilled harpooner aboard the Monroe. As for the number of whales he killed, I cannae give ye an exact count, mate. You see, the sea is a vast and unpredictable place, and Ned's adventures were many. But rest assured, Ned Land's harpoon found its mark more times than ye can count on yer fingers and toes. The ocean be teeming with magnificent creatures, and Ned Land was a force to be reckoned with when it came to hunting 'em down.\n"}]}]}